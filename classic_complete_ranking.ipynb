{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classic_complete_ranking.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t_bV546-3JVF"
      },
      "source": [
        "## Импорты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcDfknc7O0JA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip3 install matplotlib tqdm numpy torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SGIPKkSG3JVG",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm_notebook, trange, tqdm\n",
        "import pickle\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "import jedi\n",
        "import tokenize\n",
        "from io import BytesIO\n",
        "import timeit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oa2jzP-N3JVI",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1WoL992vCADZ",
        "outputId": "59a283dc-3c61-41bc-80f7-411ded5e9f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLWrw7ijQLtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c2a570e8-30d1-4afb-8b2b-a419c3dde789"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eZ7DbZnQS3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path = '/content/drive/My Drive/vkr'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMEg_bF5O0JP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "* суммирую все эмбеддинги, которые встретил до текущего ключевого слова, конкатенирую к эмбеддингу текущего слова\n",
        "    - итерируюсь по файлам из train_files.txt\n",
        "    - иду с помощью tokenize + isidentifier(), выбираю из кода identifiers, которые есть в mapping.map\n",
        "        - может ли регулярка возвращать индекс начала распознанного слова?\n",
        "        - сохраняю в массив `[[identifier, index], [...], ...]`\n",
        "    - предсохраняю номера токенов, которые войдут в сумму\n",
        "    - подаю в jedi предыдущий код + первую букву identifier'а (индекс от регулярки + 1)\n",
        "    - итерируюсь по предсказаниям и добавляю объекты в train такого вида:\n",
        "    ```\n",
        "    [\n",
        "        arr_of_prev_tokens,\n",
        "        predicted_token (число из mapping.map),\n",
        "        real_token (число из mapping.map)\n",
        "    ]```\n",
        "    - дамплю в пикл `{file_name: train}`\n",
        "* подаю на вход полносвязному слою\n",
        "* беру сигмоиду\n",
        "* подаю в кросс-энтропию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qJOR5-QO0JQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "X0rv2Bd7O0JS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# times_dict = {\n",
        "#     'code_read': [],\n",
        "#     'tokenize': [],\n",
        "#     'before_jedi': [],\n",
        "#     'jedi': [],\n",
        "#     'after_jedi': [],\n",
        "#     'everything_in_for_in_g_body': [],\n",
        "#     'save_preprocessed': [],\n",
        "# }\n",
        "\n",
        "\n",
        "# def prepare_samples(path, samples_path):\n",
        "#     def get_filenames(path):\n",
        "#         with open(path) as f:\n",
        "#             filenames = f.read().split('\\n')\n",
        "#         return filenames\n",
        "    \n",
        "#     def load_mapping(path):\n",
        "#         with open(path, 'rb') as f:\n",
        "# #         print(base_path + '/mapping.map')\n",
        "#             word_to_id = pickle.load(f)\n",
        "#         return word_to_id\n",
        "\n",
        "#     def predict_tokens(code):\n",
        "#         try:\n",
        "#             script = jedi.Script(code)\n",
        "#             return script.completions()\n",
        "#         except KeyError:\n",
        "#             pass\n",
        "# #             prepare_samples(path, samples_path)\n",
        "    \n",
        "#     def load_preprocessed(path):\n",
        "#         try:\n",
        "#             with open(path, 'rb') as f:\n",
        "#                 samples = pickle.load(f)\n",
        "#         except FileNotFoundError:\n",
        "#             samples = {}\n",
        "#         return samples\n",
        "    \n",
        "#     def save_preprocessed(samples_dict_path, samples_dict):\n",
        "#         with open(samples_dict_path, 'wb') as f:\n",
        "#             samples = pickle.dump(samples_dict, f)\n",
        "    \n",
        "#     filenames = get_filenames(path + samples_path)\n",
        "#     word_to_id = load_mapping('./mapping.map')\n",
        "    \n",
        "#     samples_dict_path = './ranking_samples_' + samples_path[:3]\n",
        "#     samples_dict = load_preprocessed(samples_dict_path)\n",
        "\n",
        "# #     start_time = timeit.default_timer()\n",
        "# #     # code you want to evaluate\n",
        "# #     elapsed = timeit.default_timer() - start_time\n",
        "\n",
        "#     for i, filename in enumerate(tqdm(filenames)):\n",
        "        \n",
        "#         if filename in samples_dict:\n",
        "#             continue\n",
        "\n",
        "# #         clear_output()\n",
        "#         times_dict['code_read'].append(0.)\n",
        "#         times_dict['tokenize'].append(0.)\n",
        "#         times_dict['before_jedi'].append(0.)\n",
        "#         times_dict['jedi'].append(0.)\n",
        "#         times_dict['after_jedi'].append(0.)\n",
        "#         times_dict['everything_in_for_in_g_body'].append(0.)\n",
        "#         times_dict['save_preprocessed'].append(0.)\n",
        "\n",
        "#         start_time = timeit.default_timer()\n",
        "#         with open(path + filename) as f:\n",
        "#             code = f.read()\n",
        "#         times_dict['code_read'][-1] += timeit.default_timer() - start_time\n",
        "#         print(times_dict['code_read'])\n",
        "        \n",
        "#         start_time = timeit.default_timer()\n",
        "#         samples = []\n",
        "#         prev_tokens = []\n",
        "#         g = tokenize.tokenize(BytesIO(code.encode(\"utf-8\")).readline)\n",
        "#         code_lines = code.split('\\n')\n",
        "#         times_dict['tokenize'][-1] += timeit.default_timer() - start_time\n",
        "#         print(times_dict['tokenize'])\n",
        "        \n",
        "#         start_time = timeit.default_timer()\n",
        "#         for toktype, tokval, start, _, _ in g:\n",
        "#             if toktype == tokenize.NAME and tokval in word_to_id:\n",
        "#                 inner_start_time = timeit.default_timer()\n",
        "#                 row, col = start\n",
        "#                 real_token = word_to_id[tokval]\n",
        "#                 prev_code = '\\n'.join(code_lines[:row-1]) + '\\n' + code_lines[row-1][:col+1]\n",
        "#                 times_dict['before_jedi'][-1] += timeit.default_timer() - inner_start_time\n",
        "                \n",
        "#                 inner_start_time = timeit.default_timer()\n",
        "#                 preds = predict_tokens(prev_code)\n",
        "#                 times_dict['jedi'][-1] += timeit.default_timer() - inner_start_time\n",
        "\n",
        "#                 inner_start_time = timeit.default_timer()\n",
        "#                 for pred in preds:\n",
        "#                     completion = pred.full_name\n",
        "#                     if completion in word_to_id:\n",
        "#                         completion_id = word_to_id[completion]\n",
        "#                         samples.append([\n",
        "#                             prev_tokens[:],\n",
        "#                             completion_id,\n",
        "#                             real_token\n",
        "#                         ])\n",
        "#                 prev_tokens.append(real_token)\n",
        "#                 times_dict['after_jedi'][-1] += timeit.default_timer() - inner_start_time\n",
        "# #                     break\n",
        "#         times_dict['everything_in_for_in_g_body'][-1] += timeit.default_timer() - start_time\n",
        "#         print(times_dict['everything_in_for_in_g_body'])\n",
        "#         samples_dict[filename] = samples\n",
        "        \n",
        "#         start_time = timeit.default_timer()\n",
        "#         save_preprocessed(samples_dict_path, samples_dict)\n",
        "#         times_dict['save_preprocessed'][-1] += timeit.default_timer() - start_time\n",
        "#         clear_output()\n",
        "# #         break\n",
        "#     save_preprocessed(samples_dict_path, samples_dict)\n",
        "#     return samples_dict\n",
        "\n",
        "# path = './pycodesuggest_py_repos_normalised/'\n",
        "# samples_path = 'train_files.txt'\n",
        "# samples = prepare_samples(path, samples_path)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMevG8jJO0JW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# times_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy0O6zu5O0Ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zICsw6fUO0Jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E5C7uycO0Jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(base_path + '/ranking_samples_tra', 'rb') as f:\n",
        "    samples = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRbpZAj6O0Jk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c67b779e-693f-4424-bcb3-2bac25db2cb9"
      },
      "source": [
        "count = 0\n",
        "\n",
        "for v in samples.values():\n",
        "    count += len(v)\n",
        "print(count)\n",
        "print(len(samples.values()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90017\n",
            "126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD74Psr9O0Jm",
        "colab_type": "text"
      },
      "source": [
        "## create test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eESPG62NO0Jn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGmvgfxXO0Jp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# jedi_correct = 900.0\n",
        "# jedi_total = 5984.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kNz5_DBbO0Js",
        "colab_type": "code",
        "colab": {},
        "outputId": "804159c1-26a0-4192-99dc-7efff35a0e83"
      },
      "source": [
        "# def prepare_test_samples(path, samples_path):\n",
        "#     global jedi_correct, jedi_total\n",
        "\n",
        "#     def get_filenames(path):\n",
        "#         with open(path) as f:\n",
        "#             filenames = f.read().split('\\n')\n",
        "#         return filenames\n",
        "    \n",
        "#     def load_mapping(path):\n",
        "#         with open(path, 'rb') as f:\n",
        "# #         print(base_path + '/mapping.map')\n",
        "#             word_to_id = pickle.load(f)\n",
        "#         return word_to_id\n",
        "\n",
        "#     def predict_tokens(code):\n",
        "#         try:\n",
        "#             script = jedi.Script(code)\n",
        "#             return script.completions()\n",
        "#         except KeyError:\n",
        "#             pass\n",
        "# #             prepare_samples(path, samples_path)\n",
        "\n",
        "#     def save_preprocessed(samples_dict_path, samples_dict):\n",
        "#         with open(samples_dict_path, 'wb') as f:\n",
        "#             pickle.dump(samples_dict, f)\n",
        "    \n",
        "#     def load_preprocessed(path):\n",
        "#         try:\n",
        "#             with open(path, 'rb') as f:\n",
        "#                 samples = pickle.load(f)\n",
        "#         except FileNotFoundError:\n",
        "#             samples = {}\n",
        "#         return samples\n",
        "    \n",
        "#     def handle_identifier(toktype, tokval, start):\n",
        "#         global jedi_correct, jedi_total\n",
        "#         row, col = start\n",
        "#         real_token = word_to_id[tokval]\n",
        "#         prev_code = '\\n'.join(code_lines[:row-1]) + '\\n' + code_lines[row-1][:col+1]\n",
        "\n",
        "#         preds = predict_tokens(prev_code)\n",
        "\n",
        "#         for idx, pred in enumerate(preds):\n",
        "#             completion = pred.full_name\n",
        "#             if idx == 0:\n",
        "#                 if completion == tokval:\n",
        "#                     jedi_correct += 1\n",
        "#                 jedi_total += 1\n",
        "#             if completion in word_to_id:\n",
        "#                 completion_id = word_to_id[completion]\n",
        "#                 samples.append([\n",
        "#                     prev_tokens[:],\n",
        "#                     completion_id,\n",
        "#                     real_token\n",
        "#                 ])\n",
        "#         prev_tokens.append(real_token)\n",
        "    \n",
        "#     filenames_for_test = get_filenames(path + samples_path)#[::-1]\n",
        "#     word_to_id = load_mapping('./mapping.map')\n",
        "    \n",
        "#     samples_dict_path = './ranking_samples_' + samples_path[:3]\n",
        "#     samples_dict = load_preprocessed(samples_dict_path)\n",
        "\n",
        "#     for i, filename in enumerate(tqdm_notebook(filenames_for_test)):\n",
        "        \n",
        "#         if filename in samples_dict:\n",
        "#             continue\n",
        "\n",
        "#         with open(path + filename) as f:\n",
        "#             code = f.read()\n",
        "#         print(path + filename)\n",
        "\n",
        "#         samples = []\n",
        "#         prev_tokens = []\n",
        "#         g = tokenize.tokenize(BytesIO(code.encode(\"utf-8\")).readline)\n",
        "#         code_lines = code.split('\\n')\n",
        "\n",
        "#         # todo accuracy plot\n",
        "#         for toktype, tokval, start, _, _ in g:\n",
        "#             if toktype == tokenize.NAME and tokval in word_to_id:\n",
        "#                 handle_identifier(toktype, tokval, start)\n",
        "        \n",
        "#         samples_dict[filename] = samples\n",
        "\n",
        "#         save_preprocessed(samples_dict_path, samples_dict)\n",
        "#         clear_output()\n",
        "#         print('Jedi accuracy: {}/{}={:.4f}'.format(jedi_correct, jedi_total, jedi_correct / jedi_total))\n",
        "# #         break\n",
        "#     save_preprocessed(samples_dict_path, samples_dict)\n",
        "#     return samples_dict\n",
        "\n",
        "# path = './pycodesuggest_py_repos_normalised/'\n",
        "# samples_path = 'test_files.txt' # todo due to word_to_id may not work\n",
        "# samples, jedi_ = prepare_test_samples(path, samples_path)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06d388a34ba943b3afb07ec1924f6d40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=39791), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "./pycodesuggest_py_repos_normalised/conda-forge/staged-recipes/.ci_support/compute_build_graph.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidPythonEnvironment",
          "evalue": "Could not get version information for '/usr/local/opt/python/bin/python3.7': BlockingIOError(35, 'Resource temporarily unavailable')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/jedi/cache.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ((), frozenset())",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mBlockingIOError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/jedi/api/environment.py\u001b[0m in \u001b[0;36m_get_subprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompiledSubprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_executable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_get_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/jedi/evaluate/compiled/subprocess/__init__.py\u001b[0m in \u001b[0;36m_send\u001b[0;34m(self, evaluator_id, function, args, kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mpickle_dump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/jedi/cache.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mdct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/jedi/evaluate/compiled/subprocess/__init__.py\u001b[0m in \u001b[0;36m_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;31m# (this is already the case on Python 3).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mbufsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/jedi/_compatibility.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'close_fds'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'posix'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_module_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGeneralizedPopen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    776\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1452\u001b[0m                             \u001b[0merrpipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrpipe_write\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m                             restore_signals, start_new_session, preexec_fn)\n\u001b[0m\u001b[1;32m   1454\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_child_created\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBlockingIOError\u001b[0m: [Errno 35] Resource temporarily unavailable",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidPythonEnvironment\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-9f1931c4f6cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./pycodesuggest_py_repos_normalised/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0msamples_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test_files.txt'\u001b[0m \u001b[0;31m# todo due to word_to_id may not work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjedi_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_test_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-9f1931c4f6cc>\u001b[0m in \u001b[0;36mprepare_test_samples\u001b[0;34m(path, samples_path)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtoktype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNAME\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtokval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_to_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mhandle_identifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0msamples_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-9f1931c4f6cc>\u001b[0m in \u001b[0;36mhandle_identifier\u001b[0;34m(toktype, tokval, start)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprev_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcode_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-9f1931c4f6cc>\u001b[0m in \u001b[0;36mpredict_tokens\u001b[0;34m(code)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjedi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/jedi/api/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, line, column, path, encoding, sys_path, environment)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mproject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sys_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         self._evaluator = Evaluator(\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscript_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         )\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_project\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/jedi/evaluate/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, project, environment, script_path)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_subprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_evaluator_subprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrammar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_grammar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/jedi/api/environment.py\u001b[0m in \u001b[0;36mget_evaluator_subprocess\u001b[0;34m(self, evaluator)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_evaluator_subprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mEvaluatorSubprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_subprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mmemoize_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/jedi/api/environment.py\u001b[0m in \u001b[0;36m_get_subprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \"Could not get version information for %r: %r\" % (\n\u001b[1;32m     78\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_executable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                     exc))\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Since it could change and might not be the same(?) as the one given,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidPythonEnvironment\u001b[0m: Could not get version information for '/usr/local/opt/python/bin/python3.7': BlockingIOError(35, 'Resource temporarily unavailable')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBQCFiK8O0Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_preprocessed(path):\n",
        "    try:\n",
        "        with open(path, 'rb') as f:\n",
        "            samples = pickle.load(f)\n",
        "    except FileNotFoundError:\n",
        "        samples = {}\n",
        "    return samples\n",
        "\n",
        "test_samples = load_preprocessed(base_path + '/ranking_samples_tes')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "M21D4oh0O0Jy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a2c6d914-c9b0-41c5-9604-2cbdb86acbc5"
      },
      "source": [
        "count = 0\n",
        "\n",
        "for v in test_samples.values():\n",
        "    count += len(v)\n",
        "print(count)\n",
        "print(len(test_samples.values()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14606\n",
            "79\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "809rWDozO0J2",
        "colab_type": "text"
      },
      "source": [
        "# Model\n",
        "\n",
        "\n",
        "* модель — Dense layer\n",
        "* как обучаем: обрабатываем сохраненные в ranking_samples_tra данные, предлагаем слою по фичам (конкатенация текущего токена и сумма предыдущих + является ли текущий токен identfier) предсказать вероятность того, что это правильный токен\n",
        "* как тестируем: делаем также, как и создавали обучающую выборку:  обновляем accuracy с каждым шагом (+ график accuracy)\n",
        "* эмбеддинги слов, подаем конкатенацию суммы эмбеддингов и эмбеддинга текущего токена, предсказанного jedi; среди многих выбираем тот, в котором модель наиболее уверена"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elFmh-riO0J3",
        "colab_type": "text"
      },
      "source": [
        "## training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uErs-C1CO0J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab():\n",
        "    # load pre-computed vocab\n",
        "    with open(base_path + '/mapping.map', 'rb') as f:\n",
        "#         print(base_path + '/mapping.map')\n",
        "        word_to_id = pickle.load(f)\n",
        "    id_to_word = dict([(v, k) for (k, v) in word_to_id.items()])\n",
        "    return word_to_id, id_to_word\n",
        "\n",
        "word_to_id, id_to_word = build_vocab()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5SpgV0CO0KD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\n",
        "    'vocab_size': len(id_to_word),\n",
        "    'emb_size': 100,\n",
        "    'batch_size': 64\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PfUZAOeO0KF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DenseModel(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super().__init__()\n",
        "        self.params = params\n",
        "        self.embedding = nn.Embedding(\n",
        "            self.params['vocab_size'] + 1,\n",
        "            self.params['emb_size']\n",
        "        )\n",
        "        self.linear = nn.Linear(\n",
        "            self.params['emb_size'] * 2,\n",
        "            1\n",
        "        )\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, prev_tokens, pred_token):\n",
        "        if prev_tokens.shape[0] == 0:\n",
        "            prev_tokens = torch.LongTensor([self.params['vocab_size']]).to(device)\n",
        "#         print(prev_tokens)\n",
        "        prev_embs = self.embedding(prev_tokens)\n",
        "#         print(prev_embs)\n",
        "#         print(prev_embs.shape)\n",
        "        prev_embs_mean = torch.mean(prev_embs, dim=0)\n",
        "        pred_emb = self.embedding(pred_token)\n",
        "        pred_emb = torch.squeeze(pred_emb)\n",
        "#         print(prev_embs_mean.shape)\n",
        "#         print(pred_emb.shape)\n",
        "        inputs = torch.cat((prev_embs_mean, pred_emb))\n",
        "#         print(inputs.shape)\n",
        "        output = self.linear(inputs)\n",
        "#         print(output.shape)\n",
        "        output = self.activation(output)\n",
        "#         print(output.shape)\n",
        "        return output\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZanB86xO0KJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = DenseModel(params).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb-9i4G6O0KM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN5mRdfGO0KP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class JediPredsDataset():\n",
        "    def preprocess_data(self, filenames_to_data_dict):\n",
        "        for data in filenames_to_data_dict.values():\n",
        "            for prev_tokens, pred_token, real_token in data:\n",
        "                self.prev_tokens_arr.append(np.array(prev_tokens))\n",
        "                self.pred_token_arr.append(pred_token)\n",
        "                self.real_token_arr.append(real_token)\n",
        "\n",
        "    def __init__(self, path, params):\n",
        "        self.index = 0\n",
        "        self.prev_tokens_arr = []\n",
        "        self.pred_token_arr = []\n",
        "        self.real_token_arr = []\n",
        "\n",
        "        with open(path, 'rb') as f:\n",
        "            filenames_to_data_dict = pickle.load(f)\n",
        "        self.preprocess_data(filenames_to_data_dict)\n",
        "        self.prev_tokens_arr = np.array(self.prev_tokens_arr)\n",
        "        self.pred_token_arr = np.array(self.pred_token_arr)\n",
        "        self.real_token_arr = np.array(self.real_token_arr)\n",
        "        # todo shuffle\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.real_token_arr.shape[0]\n",
        "\n",
        "    def generator(self):\n",
        "        while self.index < self.__len__():\n",
        "            yield \\\n",
        "                self.prev_tokens_arr[self.index], \\\n",
        "                self.pred_token_arr[self.index], \\\n",
        "                self.real_token_arr[self.index]\n",
        "            self.index += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUPbe2ZsO0KT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# train_loader = DataLoader(\n",
        "#     JediPredsDataset('./ranking_samples_tra', params),\n",
        "#     batch_size=params['batch_size'],\n",
        "#     shuffle=True,\n",
        "#     num_workers=10\n",
        "# )\n",
        "\n",
        "# train_data = JediPredsDataset(base_path + '/ranking_samples_tra', params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PezYlV-MQviO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93ff01e8-ff27-4acf-d927-7c2724b04dda"
      },
      "source": [
        "# eq = 0\n",
        "# neq = 0\n",
        "# for prev_tokens, pred_token, real_token in train_data.generator():\n",
        "#     if pred_token == real_token:\n",
        "#         eq += 1\n",
        "#     else:\n",
        "#         neq += 1\n",
        "# print(eq, neq, eq+neq)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7874 82143 90017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PAYDuDQO0Ka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# next(train_data.generator())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP4HHMuZO0Ke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i, (prev_tokens, pred_token, real_token) in zip(trange(len(train_data)), train_data.generator()):\n",
        "#     print(1)\n",
        "#     print(prev_tokens, pred_token, real_token)\n",
        "#     print(2)\n",
        "#     break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXd91ZZcO0Kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model, optimizer, lr, train_data):\n",
        "    loss_log = []\n",
        "    model.train()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    \n",
        "    for i, (prev_tokens, pred_token, real_token) in zip(trange(len(train_data)), train_data.generator()):\n",
        "        optimizer.zero_grad()\n",
        "        prev_tokens = torch.LongTensor(prev_tokens).to(device)\n",
        "        pred_token = torch.LongTensor([pred_token]).to(device)\n",
        "        real_token = torch.FloatTensor([real_token]).to(device)\n",
        "        loss_value = 0.\n",
        "        loss = nn.BCELoss()\n",
        "        output = model.forward(prev_tokens, pred_token)\n",
        "        \n",
        "#         print(real_token)\n",
        "#         print(pred_token.float())\n",
        "#         print(real_token == pred_token.float())\n",
        "        loss_value = loss(output, (real_token == pred_token.float()).float())\n",
        "        loss_value.backward()\n",
        "\n",
        "#         torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
        "#         for p in model.parameters():\n",
        "#             p.data.add_(-lr, p.grad.data)\n",
        "        optimizer.step()\n",
        "        loss_value = loss_value.item()\n",
        "        loss_log.append(loss_value)# / x.shape[1])\n",
        "#         break\n",
        "\n",
        "#     accuracy = correct / total\n",
        "#     return accuracy, loss_log\n",
        "    return loss_log\n",
        "    \n",
        "def train(model, opt, n_epochs):\n",
        "    train_log = []\n",
        "    acc_log = []\n",
        "    lr = 0.05\n",
        "    lr_decay_base = 1 / 1.15\n",
        "    m_flat_lr = 20.0\n",
        "    for epoch in range(n_epochs):\n",
        "        lr_decay = lr_decay_base ** max(epoch - m_flat_lr, 0)\n",
        "        lr = lr * lr_decay\n",
        "#         accuracy, train_loss = train_epoch(model, opt, lr)\n",
        "        train_data = JediPredsDataset(base_path + '/ranking_samples_tra', params)\n",
        "        train_loss = train_epoch(model, opt, lr, train_data)\n",
        "        train_log.extend(train_loss)\n",
        "#         acc_log.append(accuracy)\n",
        "        clear_output()\n",
        "        print(\"Epoch:{}\".format(epoch))\n",
        "#         print(\"Accuracy:\", accuracy)\n",
        "#         tp.send_text('Epoch {}, LSTM baseline accuracy: {}'.format(epoch, accuracy))\n",
        "        plot_history(train_log)\n",
        "\n",
        "def plot_history(train_history, title='loss'):\n",
        "    plt.figure()\n",
        "    plt.title('{}'.format(title))\n",
        "    plt.plot(train_history, label='train', zorder=1)\n",
        "    plt.xlabel('train steps')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RCwWqHxO0Kp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "99b1b975-be29-40e7-ac25-61162903a7bd"
      },
      "source": [
        "# %%time\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "train(model, optimizer, 5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEWCAYAAAB2X2wCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "HlsLpyPhO0Kw",
        "colab_type": "code",
        "colab": {},
        "outputId": "d0ea4480-b5b8-4d29-becf-2019c1252c19"
      },
      "source": [
        "# prev_tokens, pred_token, _ = samples[0][0]\n",
        "# model.eval()\n",
        "# model.forward(torch.LongTensor(prev_tokens), torch.LongTensor([pred_token]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([8.0516e-07], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sztgAaPVO0Ky",
        "colab_type": "text"
      },
      "source": [
        "### тестируем пошагово"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJVbCd_mO0Kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIg8KkTAO0K1",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhuYnxrnO0K1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = JediPredsDataset(base_path + '/ranking_samples_tes', params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou8qrkRoO0K3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def test(model):\n",
        "    loss_log = []\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    prev_prevtokens, prev_realtoken = None, None\n",
        "    outputs = []\n",
        "    for i, (prev_tokens, pred_token, real_token) in zip(trange(len(test_data)), test_data.generator()):\n",
        "        prev_tokens_t = torch.LongTensor(prev_tokens).to(device)\n",
        "        pred_token_t = torch.LongTensor([pred_token]).to(device)\n",
        "#         real_token_t = torch.FloatTensor([real_token]).to(device)\n",
        "        output = model.forward(prev_tokens_t, pred_token_t)\n",
        "\n",
        "        if np.all(prev_tokens == prev_prevtokens) and \\\n",
        "                prev_realtoken == real_token:\n",
        "            outputs.append([pred_token, output])\n",
        "        else:\n",
        "            if prev_realtoken is not None:\n",
        "                max_prob = 0.\n",
        "                pred = None\n",
        "                for o in outputs:\n",
        "                    if o[1] > max_prob:\n",
        "                        max_prob = o[1]\n",
        "                        pred = o[0]\n",
        "                if pred == real_token:\n",
        "                    correct += 1\n",
        "                total += 1\n",
        "            \n",
        "            outputs = [[pred_token, output]]\n",
        "            \n",
        "            prev_prevtokens = prev_tokens\n",
        "            prev_realtoken = real_token\n",
        "                \n",
        "#     accuracy = correct / total\n",
        "    return correct, total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlfc3dLfO0K4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e9cd0f00-d917-498c-fbb8-aa7ffe289c67"
      },
      "source": [
        "correct, total = test(model)\n",
        "correct, total"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/14606 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  from ipykernel import kernelapp as app\n",
            "100%|██████████| 14606/14606 [00:05<00:00, 2825.81it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 4068)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQNBLWrTO0K6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bef0c75-7bd4-4163-b724-0e0ad8c04075"
      },
      "source": [
        "correct / total"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.006391347099311701"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jZD7I9iSkVs",
        "colab_type": "text"
      },
      "source": [
        "# Let's test test\n",
        "Because ranking is quite bad (0.006 acc) while jedi is good (0.15 acc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMOuMhdeSkya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def test(model):\n",
        "    loss_log = []\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    prev_prevtokens, prev_realtoken = None, None\n",
        "    test_data = JediPredsDataset(base_path + '/ranking_samples_tes', params)\n",
        "    for i, (prev_tokens, pred_token, real_token) in zip(trange(len(test_data)), test_data.generator()):\n",
        "        prev_tokens_t = torch.LongTensor(prev_tokens).to(device)\n",
        "        pred_token_t = torch.LongTensor([pred_token]).to(device)\n",
        "#         real_token_t = torch.FloatTensor([real_token]).to(device)\n",
        "#         output = model.forward(prev_tokens_t, pred_token_t)\n",
        "\n",
        "        if np.all(prev_tokens == prev_prevtokens) and \\\n",
        "                prev_realtoken == real_token:\n",
        "            pass\n",
        "        else:\n",
        "            if prev_realtoken is not None:\n",
        "                if pred_token == real_token:\n",
        "                    correct += 1\n",
        "                total += 1\n",
        "            \n",
        "            prev_prevtokens = prev_tokens\n",
        "            prev_realtoken = real_token\n",
        "                \n",
        "#     accuracy = correct / total\n",
        "    return correct, total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5x_DbpDS8XM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "debe9ee1-5ca7-43ed-f105-c5eaee9ebc12"
      },
      "source": [
        "correct, total = test(model)\n",
        "correct, total"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/14606 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  from ipykernel import kernelapp as app\n",
            "100%|██████████| 14606/14606 [00:00<00:00, 17360.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(601, 4068)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YwUZTnFTScm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5f9be67-8cb6-4c60-a5f5-ae4902deec13"
      },
      "source": [
        "correct / total"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14773844641101277"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzAKhFDkO0K8",
        "colab_type": "text"
      },
      "source": [
        "# Del"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqMKLKvkO0K9",
        "colab_type": "text"
      },
      "source": [
        "# Playing with jedi module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLwj5UFMO0LA",
        "colab_type": "code",
        "colab": {},
        "outputId": "af25017a-3d74-455c-e920-ef5f3adb181f"
      },
      "source": [
        "code = '''from __future__ import print_function\n",
        "from socket import timeout\n",
        "import os\n",
        "import sys\n",
        "import codecs\n",
        "import re\n",
        "import markdown\n",
        "try:\n",
        "    from urllib2 import urlopen\n",
        "    from urllib2 import HTTPError\n",
        "    from urllib2 import URLError\n",
        "except ImportError:\n",
        "    from urllib.request import urlopen\n",
        "    from urllib.error import HTTPError\n",
        "    from urllib.error import URLError\n",
        "\n",
        "\n",
        "def function874(arg89):\n",
        "    var4252 = False\n",
        "    try:\n",
        "        var4262 = urlopen(arg89, timeout=2)\n",
        "        var4252 = var4262.code == 200\n",
        "    except HTTPError as var3998:\n",
        "        print(var3998, file=sys.stderr)\n",
        "    except URLError as var3998:\n",
        "        print(var3998, file=sys.stderr)\n",
        "    except timeout as var3998:\n",
        "        print(var3998, file=sys.stderr)\n",
        "    except Exception as var3998:\n",
        "        print(var3998, file=sys.stderr)\n",
        "    return v'''\n",
        "\n",
        "iter_num = 10\n",
        "for i in range(iter_num):\n",
        "    start_time = timeit.default_timer()\n",
        "    script = jedi.Script(code)#source, 3, len('datetime.da'), 'example.py')\n",
        "    elapsed_time = timeit.default_timer() - start_time\n",
        "print(elapsed_time / iter_num)\n",
        "script.completions()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.013895298199986427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Completion: var3998>,\n",
              " <Completion: var4252>,\n",
              " <Completion: var4262>,\n",
              " <Completion: vars>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke0j7G6eO0LE",
        "colab_type": "code",
        "colab": {},
        "outputId": "6a494682-4dcd-46bf-84ec-68b5dbdd2bee"
      },
      "source": [
        "code = '''\n",
        "def foo(i):\n",
        "'''\n",
        "\n",
        "script = jedi.Script(code)#source, 3, len('datetime.da'), 'example.py')\n",
        "script.completions()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Completion: abs>,\n",
              " <Completion: all>,\n",
              " <Completion: any>,\n",
              " <Completion: ArithmeticError>,\n",
              " <Completion: ascii>,\n",
              " <Completion: assert>,\n",
              " <Completion: AssertionError>,\n",
              " <Completion: async>,\n",
              " <Completion: AttributeError>,\n",
              " <Completion: await>,\n",
              " <Completion: BaseException>,\n",
              " <Completion: bin>,\n",
              " <Completion: BlockingIOError>,\n",
              " <Completion: bool>,\n",
              " <Completion: break>,\n",
              " <Completion: breakpoint>,\n",
              " <Completion: BrokenPipeError>,\n",
              " <Completion: BufferError>,\n",
              " <Completion: bytearray>,\n",
              " <Completion: bytes>,\n",
              " <Completion: BytesWarning>,\n",
              " <Completion: callable>,\n",
              " <Completion: ChildProcessError>,\n",
              " <Completion: chr>,\n",
              " <Completion: class>,\n",
              " <Completion: classmethod>,\n",
              " <Completion: compile>,\n",
              " <Completion: complex>,\n",
              " <Completion: ConnectionAbortedError>,\n",
              " <Completion: ConnectionError>,\n",
              " <Completion: ConnectionRefusedError>,\n",
              " <Completion: ConnectionResetError>,\n",
              " <Completion: continue>,\n",
              " <Completion: copyright>,\n",
              " <Completion: credits>,\n",
              " <Completion: def>,\n",
              " <Completion: del>,\n",
              " <Completion: delattr>,\n",
              " <Completion: DeprecationWarning>,\n",
              " <Completion: dict>,\n",
              " <Completion: dir>,\n",
              " <Completion: divmod>,\n",
              " <Completion: Ellipsis>,\n",
              " <Completion: enumerate>,\n",
              " <Completion: EnvironmentError>,\n",
              " <Completion: EOFError>,\n",
              " <Completion: eval>,\n",
              " <Completion: Exception>,\n",
              " <Completion: exec>,\n",
              " <Completion: exit>,\n",
              " <Completion: False>,\n",
              " <Completion: FileExistsError>,\n",
              " <Completion: FileNotFoundError>,\n",
              " <Completion: filter>,\n",
              " <Completion: float>,\n",
              " <Completion: FloatingPointError>,\n",
              " <Completion: for>,\n",
              " <Completion: format>,\n",
              " <Completion: from>,\n",
              " <Completion: frozenset>,\n",
              " <Completion: FutureWarning>,\n",
              " <Completion: GeneratorExit>,\n",
              " <Completion: getattr>,\n",
              " <Completion: global>,\n",
              " <Completion: globals>,\n",
              " <Completion: hasattr>,\n",
              " <Completion: hash>,\n",
              " <Completion: help>,\n",
              " <Completion: hex>,\n",
              " <Completion: id>,\n",
              " <Completion: if>,\n",
              " <Completion: import>,\n",
              " <Completion: ImportError>,\n",
              " <Completion: ImportWarning>,\n",
              " <Completion: IndentationError>,\n",
              " <Completion: IndexError>,\n",
              " <Completion: input>,\n",
              " <Completion: int>,\n",
              " <Completion: InterruptedError>,\n",
              " <Completion: IOError>,\n",
              " <Completion: IsADirectoryError>,\n",
              " <Completion: isinstance>,\n",
              " <Completion: issubclass>,\n",
              " <Completion: iter>,\n",
              " <Completion: KeyboardInterrupt>,\n",
              " <Completion: KeyError>,\n",
              " <Completion: lambda>,\n",
              " <Completion: len>,\n",
              " <Completion: license>,\n",
              " <Completion: list>,\n",
              " <Completion: locals>,\n",
              " <Completion: LookupError>,\n",
              " <Completion: map>,\n",
              " <Completion: max>,\n",
              " <Completion: MemoryError>,\n",
              " <Completion: memoryview>,\n",
              " <Completion: min>,\n",
              " <Completion: ModuleNotFoundError>,\n",
              " <Completion: NameError>,\n",
              " <Completion: next>,\n",
              " <Completion: None>,\n",
              " <Completion: nonlocal>,\n",
              " <Completion: not>,\n",
              " <Completion: NotADirectoryError>,\n",
              " <Completion: NotImplemented>,\n",
              " <Completion: NotImplementedError>,\n",
              " <Completion: object>,\n",
              " <Completion: oct>,\n",
              " <Completion: open>,\n",
              " <Completion: ord>,\n",
              " <Completion: OSError>,\n",
              " <Completion: OverflowError>,\n",
              " <Completion: pass>,\n",
              " <Completion: PendingDeprecationWarning>,\n",
              " <Completion: PermissionError>,\n",
              " <Completion: pow>,\n",
              " <Completion: print>,\n",
              " <Completion: ProcessLookupError>,\n",
              " <Completion: property>,\n",
              " <Completion: quit>,\n",
              " <Completion: raise>,\n",
              " <Completion: range>,\n",
              " <Completion: RecursionError>,\n",
              " <Completion: ReferenceError>,\n",
              " <Completion: repr>,\n",
              " <Completion: ResourceWarning>,\n",
              " <Completion: return>,\n",
              " <Completion: reversed>,\n",
              " <Completion: round>,\n",
              " <Completion: RuntimeError>,\n",
              " <Completion: RuntimeWarning>,\n",
              " <Completion: set>,\n",
              " <Completion: setattr>,\n",
              " <Completion: slice>,\n",
              " <Completion: sorted>,\n",
              " <Completion: staticmethod>,\n",
              " <Completion: StopAsyncIteration>,\n",
              " <Completion: StopIteration>,\n",
              " <Completion: str>,\n",
              " <Completion: sum>,\n",
              " <Completion: super>,\n",
              " <Completion: SyntaxError>,\n",
              " <Completion: SyntaxWarning>,\n",
              " <Completion: SystemError>,\n",
              " <Completion: SystemExit>,\n",
              " <Completion: TabError>,\n",
              " <Completion: TimeoutError>,\n",
              " <Completion: True>,\n",
              " <Completion: try>,\n",
              " <Completion: tuple>,\n",
              " <Completion: type>,\n",
              " <Completion: TypeError>,\n",
              " <Completion: UnboundLocalError>,\n",
              " <Completion: UnicodeDecodeError>,\n",
              " <Completion: UnicodeEncodeError>,\n",
              " <Completion: UnicodeError>,\n",
              " <Completion: UnicodeTranslateError>,\n",
              " <Completion: UnicodeWarning>,\n",
              " <Completion: UserWarning>,\n",
              " <Completion: ValueError>,\n",
              " <Completion: vars>,\n",
              " <Completion: Warning>,\n",
              " <Completion: while>,\n",
              " <Completion: with>,\n",
              " <Completion: yield>,\n",
              " <Completion: ZeroDivisionError>,\n",
              " <Completion: zip>,\n",
              " <Completion: __build_class__>,\n",
              " <Completion: __debug__>,\n",
              " <Completion: __doc__>,\n",
              " <Completion: __file__>,\n",
              " <Completion: __import__>,\n",
              " <Completion: __loader__>,\n",
              " <Completion: __name__>,\n",
              " <Completion: __package__>,\n",
              " <Completion: __spec__>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-Wna-WHO0LI",
        "colab_type": "code",
        "colab": {},
        "outputId": "a9cf09b0-5610-4f8b-e4f7-aef77cfd8f64"
      },
      "source": [
        "import tokenize\n",
        "from io import BytesIO\n",
        "from keyword import iskeyword\n",
        "\n",
        "def load_code(path):\n",
        "    pass\n",
        "\n",
        "def process_code(code):\n",
        "#     s = code #\n",
        "    s = \"def twoπ(a,b):\"\n",
        "    g = tokenize.tokenize(BytesIO(s.encode(\"utf-8\")).readline)\n",
        "    new_s = ''\n",
        "    for toktype, tokval, st, end, _ in g:\n",
        "        if toktype == tokenize.NAME:\n",
        "            if iskeyword(tokval):\n",
        "                print(\"KEYWORD\", tokval, tokval.isidentifier(), st)\n",
        "            else:\n",
        "                print('NAME', tokval, tokval.isidentifier(), st)\n",
        "        else:\n",
        "            print(toktype, tokval)\n",
        "        new_s += f'{tokval} '\n",
        "    print(new_s)\n",
        "\n",
        "process_code(None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57 utf-8\n",
            "KEYWORD def True (1, 0)\n",
            "NAME twoπ True (1, 4)\n",
            "53 (\n",
            "NAME a True (1, 9)\n",
            "53 ,\n",
            "NAME b True (1, 11)\n",
            "53 )\n",
            "53 :\n",
            "4 \n",
            "0 \n",
            "utf-8 def twoπ ( a , b ) :   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SG79dRtO0LM",
        "colab_type": "code",
        "colab": {},
        "outputId": "46d06361-8868-41d7-f78f-1231825f8521"
      },
      "source": [
        "print(new_s[8:].strip())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def foo ( i ) : \n",
            "      f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yus4ws1O0LQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "6e58fccc-57a6-4b95-a744-9009518f17a6"
      },
      "source": [
        "script = jedi.Script(new_s[8:].strip())\n",
        "script.completions()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Completion: filter>,\n",
              " <Completion: float>,\n",
              " <Completion: foo>,\n",
              " <Completion: for>,\n",
              " <Completion: format>,\n",
              " <Completion: from>,\n",
              " <Completion: frozenset>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QdgmtxfO0LS",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}