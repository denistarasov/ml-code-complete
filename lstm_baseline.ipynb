{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_code_data(path):\n",
    "#     for _, _, files in os.walk(path):\n",
    "#         data = np.empty((0, 100))\n",
    "#         for file in tqdm_notebook(files):\n",
    "#             with open(path + file, 'rb') as f:\n",
    "#                 array = pickle.load(f)\n",
    "#                 for i in tqdm_notebook(range(len(array)), leave=False):\n",
    "#                     data = np.concatenate((data, array[i].inputs), axis=0)\n",
    "#     return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data = get_code_data(base_path + '/after_preprocess/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ast.dump(ast.parse('if x >= 0:\\n    x = 0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(ast.parse('test_var = test_list[0]').body[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook, trange\n",
    "import pickle\n",
    "import numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/Users/dentarasov/Yandex.Disk.localized/current/vkr'\n",
    "code_batched = base_path + '/after_preprocess/after_preprocess.part0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab():\n",
    "    # load pre-computed vocab\n",
    "    with open(base_path + '/mapping.map', 'rb') as f:\n",
    "        word_to_id = pickle.load(f)\n",
    "    id_to_word = dict([(v, k) for (k, v) in word_to_id.items()])\n",
    "    return word_to_id, id_to_word\n",
    "\n",
    "word_to_id, id_to_word = build_vocab()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    'batch_size': 64,\n",
    "    'emb_size': 150,\n",
    "    'vocab_size': len(word_to_id),\n",
    "    # 'seq_len': 100,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_code_data(path):\n",
    "#     for _, _, files in os.walk(path):\n",
    "#         data = np.empty((0, 100))\n",
    "#         for file in tqdm_notebook(files):\n",
    "#             with open(path + file, 'rb') as f:\n",
    "#                 array = pickle.load(f)\n",
    "#                 for i in tqdm_notebook(range(len(array)), leave=False):\n",
    "#                     data = np.concatenate((data, array[i].inputs), axis=0)\n",
    "#     return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data = get_code_data(base_path + '/after_preprocess/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./after_preprocess/all_inputs', 'wb') as f:\n",
    "#     pickle.dump(data.astype('int64'), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = base_path + '/after_preprocess/all_inputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeDataset(Dataset):\n",
    "    def __init__(self, path, params):\n",
    "        with open(path, 'rb') as f:\n",
    "            self.data = pickle.load(f)\n",
    "        print(type(self.data))\n",
    "        print(type(self.data[0]))\n",
    "#         self.batch_size = params['batch_size']\n",
    "\n",
    "    def __len__(self):\n",
    "#         # return number of batches\n",
    "#         return int(np.ceil(self.data.shape[0] // self.batch_size))\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "#         return self.data[index * self.batch_size : (index+1) * self.batch_size]\n",
    "        return self.data[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    CodeDataset(data_path, params),\n",
    "    batch_size=params['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[0:64].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train_loader:\n",
    "#     print(type(i))\n",
    "#     print(i.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инициализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==0.7.0\r\n",
      "appnope==0.1.0\r\n",
      "asn1crypto==0.24.0\r\n",
      "astor==0.7.1\r\n",
      "atomicwrites==1.2.1\r\n",
      "attrs==18.2.0\r\n",
      "backcall==0.1.0\r\n",
      "bleach==3.0.2\r\n",
      "boto==2.49.0\r\n",
      "boto3==1.9.67\r\n",
      "botocore==1.12.67\r\n",
      "bz2file==0.98\r\n",
      "catboost==0.11.1\r\n",
      "certifi==2018.11.29\r\n",
      "cffi==1.12.2\r\n",
      "chardet==3.0.4\r\n",
      "cloudpickle==0.6.1\r\n",
      "cryptography==2.6.1\r\n",
      "cycler==0.10.0\r\n",
      "Cython==0.29.6\r\n",
      "dask==1.0.0\r\n",
      "decorator==4.3.0\r\n",
      "defusedxml==0.5.0\r\n",
      "docutils==0.14\r\n",
      "entrypoints==0.2.3\r\n",
      "enum34==1.1.6\r\n",
      "format-sql==0.12.0\r\n",
      "funcy==1.11\r\n",
      "future==0.17.1\r\n",
      "gast==0.2.2\r\n",
      "gensim==3.6.0\r\n",
      "gitdb2==2.0.5\r\n",
      "github3.py==1.3.0\r\n",
      "GitPython==2.1.11\r\n",
      "grpcio==1.18.0\r\n",
      "h5py==2.9.0\r\n",
      "idna==2.8\r\n",
      "imageio==2.5.0\r\n",
      "imageio-ffmpeg==0.2.0\r\n",
      "ipykernel==5.1.0\r\n",
      "ipython==7.1.1\r\n",
      "ipython-genutils==0.2.0\r\n",
      "ipywidgets==7.4.2\r\n",
      "jedi==0.13.1\r\n",
      "Jinja2==2.10\r\n",
      "jmespath==0.9.3\r\n",
      "joblib==0.13.0\r\n",
      "jsonschema==2.6.0\r\n",
      "jupyter==1.0.0\r\n",
      "jupyter-client==5.2.3\r\n",
      "jupyter-console==6.0.0\r\n",
      "jupyter-core==4.4.0\r\n",
      "jwcrypto==0.6.0\r\n",
      "Keras==2.2.4\r\n",
      "Keras-Applications==1.0.6\r\n",
      "Keras-Preprocessing==1.0.5\r\n",
      "kiwisolver==1.0.1\r\n",
      "Markdown==3.0.1\r\n",
      "MarkupSafe==1.1.0\r\n",
      "matplotlib==3.0.2\r\n",
      "mistune==0.8.4\r\n",
      "more-itertools==4.3.0\r\n",
      "moviepy==1.0.0\r\n",
      "nbconvert==5.4.0\r\n",
      "nbformat==4.4.0\r\n",
      "networkx==2.2\r\n",
      "nose==1.3.7\r\n",
      "notebook==5.7.2\r\n",
      "numexpr==2.6.8\r\n",
      "numpy==1.15.4\r\n",
      "opencv-python==4.0.0.21\r\n",
      "pandas==0.23.4\r\n",
      "pandocfilters==1.4.2\r\n",
      "parso==0.3.1\r\n",
      "pdfkit==0.6.1\r\n",
      "pexpect==4.6.0\r\n",
      "pickleshare==0.7.5\r\n",
      "Pillow==5.4.1\r\n",
      "pluggy==0.8.0\r\n",
      "proglog==0.1.9\r\n",
      "prometheus-client==0.4.2\r\n",
      "prompt-toolkit==2.0.7\r\n",
      "protobuf==3.6.1\r\n",
      "ptyprocess==0.6.0\r\n",
      "py==1.7.0\r\n",
      "pycparser==2.19\r\n",
      "pyflow==1.0\r\n",
      "Pygments==2.2.0\r\n",
      "pyLDAvis==2.1.2\r\n",
      "pyparsing==2.3.0\r\n",
      "pyrepo==0.1.2\r\n",
      "pytesseract==0.2.6\r\n",
      "pytest==4.0.2\r\n",
      "python-dateutil==2.7.5\r\n",
      "pytz==2018.7\r\n",
      "PyWavelets==1.0.1\r\n",
      "PyYAML==5.1\r\n",
      "pyzmq==17.1.2\r\n",
      "qtconsole==4.4.3\r\n",
      "requests==2.21.0\r\n",
      "s3transfer==0.1.13\r\n",
      "scikit-image==0.14.1\r\n",
      "scikit-learn==0.20.1\r\n",
      "scipy==1.1.0\r\n",
      "seaborn==0.9.0\r\n",
      "Send2Trash==1.5.0\r\n",
      "six==1.11.0\r\n",
      "sklearn==0.0\r\n",
      "smart-open==1.7.1\r\n",
      "smmap2==2.0.5\r\n",
      "sqlparse==0.2.4\r\n",
      "telepyth==0.1.6\r\n",
      "tensorboard==1.12.2\r\n",
      "tensorflow==1.12.0\r\n",
      "termcolor==1.1.0\r\n",
      "terminado==0.8.1\r\n",
      "testpath==0.4.2\r\n",
      "toolz==0.9.0\r\n",
      "torch==1.0.0\r\n",
      "torchvision==0.2.1\r\n",
      "tornado==5.1.1\r\n",
      "tqdm==4.28.1\r\n",
      "traitlets==4.3.2\r\n",
      "uritemplate==3.0.0\r\n",
      "urllib3==1.24.1\r\n",
      "virtualenv==16.4.1\r\n",
      "wcwidth==0.1.7\r\n",
      "webencodings==0.5.1\r\n",
      "Werkzeug==0.14.1\r\n",
      "widgetsnbextension==3.4.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmBaseline(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        self.embedding = nn.Embedding(\n",
    "            self.params['vocab_size'],\n",
    "            self.params['emb_size']\n",
    "        )\n",
    "        self.lstm = nn.LSTMCell(\n",
    "            self.params['emb_size'],\n",
    "            self.params['emb_size'],\n",
    "            2\n",
    "        )\n",
    "        self.linear = nn.Linear(\n",
    "            self.params['emb_size'],\n",
    "            self.params['vocab_size']\n",
    "        )\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        embs = self.embedding(inputs)\n",
    "#         print(hidden.shape)\n",
    "        print(embs.shape)\n",
    "        print(embs.grad)\n",
    "        # need 100, 64, 150(?)\n",
    "        # real 64, 100, 150\n",
    "        print('inputs.shape', inputs.shape)\n",
    "        output, hidden = self.lstm.forward(embs, hidden)\n",
    "        print(output.grad)\n",
    "        output = self.linear(output)\n",
    "        print(output.grad)\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(torch.from_numpy(np.arange(3)).grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, lr):\n",
    "    loss_log = []\n",
    "    model.train()\n",
    "    \n",
    "    for batch_num, x in zip(trange(len(train_loader)), train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        print(1)\n",
    "        print('x', x.grad)\n",
    "        print('x', type(x))\n",
    "        print('x', x)\n",
    "#         x = x.long()\n",
    "#         x.requires_grad = True\n",
    "\n",
    "#         x, y = x.to(device), y.to(device)\n",
    "#         params['batch_size'] = x.shape[0]\n",
    "#         p = torch.Tensor(generate_mask(params)).to(device)\n",
    "        \n",
    "        # todo 3rd parameter should be batch_size, shouldn't it?\n",
    "#         hidden = torch.zeros(2, 2, x.shape[1], params[\"emb_size\"]) #, device=device)\n",
    "\n",
    "#         output, _ = model.forward(x)\n",
    "        print(2)\n",
    "        loss_value = 0.\n",
    "#         loss = nn.CrossEntropyLoss()\n",
    "        # todo check\n",
    "        hidden = None\n",
    "        for i in tqdm_notebook(range(x.shape[1] - 1)):\n",
    "            output, hidden = model.forward(x[:, i], hidden)\n",
    "            loss_value += F.cross_entropy(output[:, i], x[:, i + 1])\n",
    "        print(3)\n",
    "        print(type(loss_value))\n",
    "        print(dir(loss_value))\n",
    "        print(loss_value.grad)\n",
    "        print(loss_value.requires_grad)\n",
    "        print(loss_value.requires_grad_)\n",
    "        loss_value.backward()\n",
    "        print(3.5)\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
    "        for p in model.parameters():\n",
    "            p.data.add_(-lr, p.grad.data)\n",
    "        optimizer.step()\n",
    "        print(4)\n",
    "        \n",
    "        loss_value = loss_value.item()\n",
    "        loss_log.append(loss_value / x.shape[1])\n",
    "    perp = np.exp(np.mean(loss_log))\n",
    "    return loss_log, perp\n",
    "\n",
    "def test(model, test_batches):\n",
    "    loss_log = []\n",
    "    model.eval()\n",
    "    for batch_num, x in zip(trange(len(train_loader)), val_loader):        \n",
    "        hidden = model.init_hidden(batch.shape[0])\n",
    "        loss = 0\n",
    "        output = model.forward(x, y)\n",
    "        loss = F.cross_entropy(output.float(), y.float())\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss / nums.shape[0])\n",
    "    return loss_log\n",
    "\n",
    "def plot_history(train_history, title='loss'):\n",
    "    plt.figure()\n",
    "    plt.title('{}'.format(title))\n",
    "    plt.plot(train_history, label='train', zorder=1)\n",
    "    plt.xlabel('train steps')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def train(model, opt, n_epochs):\n",
    "    train_log = []\n",
    "    val_log = []\n",
    "    perp_log = []\n",
    "    lr = 0.05\n",
    "    lr_decay_base = 1 / 1.15\n",
    "    m_flat_lr = 20.0\n",
    "    for epoch in range(n_epochs):\n",
    "        lr_decay = lr_decay_base ** max(epoch - m_flat_lr, 0)\n",
    "        lr = lr * lr_decay\n",
    "        train_loss, perp = train_epoch(model, opt, lr)\n",
    "        train_log.extend(train_loss)\n",
    "        perp_log.append(perp)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save(\n",
    "                {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': opt.state_dict(),\n",
    "                    'loss': train_log[-1]\n",
    "                },\n",
    "                './model_checkpoints/lstm_baseline_checkpoint_{}.pt'.format(epoch)\n",
    "            )\n",
    "        clear_output()\n",
    "        print(\"Epoch:{}\".format(epoch))\n",
    "        plot_history(train_log)\n",
    "        plot_history(perp_log)\n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': n_epochs,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'loss': train_log[-1]\n",
    "        },\n",
    "        './model_checkpoints/lstm_baseline_checkpoint_{}.pt'.format(n_epochs)\n",
    "    )\n",
    "#     np.save(\"/home/.../model_checkpoints..._logs.npy\", np.array(train_log))\n",
    "#     np.save(\"/home/.../model_checkpoints..._logs_perp.npy\", np.array(perp_log))\n",
    "    \n",
    "# model = LstmBaseline(params)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# train(model, optimizer, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LstmBaseline(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10871 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "x None\n",
      "x <class 'torch.Tensor'>\n",
      "x tensor([[    6, 25336,     6,  ...,     2,  4961,     7],\n",
      "        [   22, 65627,     2,  ...,     0,     0,     0],\n",
      "        [   23,    20,     4,  ...,    20,     4,     8],\n",
      "        ...,\n",
      "        [    4,     5,    28,  ...,    12,    17,  4853],\n",
      "        [    6,   163,     4,  ...,  2339,     5,     2],\n",
      "        [    2,    30,   124,  ...,    46,     6,  9691]])\n",
      "2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda26c94b59947b885f6f446c44b0b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 150])\n",
      "None\n",
      "inputs.shape torch.Size([64])\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-624a82af9181>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, opt, n_epochs)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mlr_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_decay_base\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mm_flat_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mtrain_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mperp_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-624a82af9181>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, lr)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mloss_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-a0b4183e8e9d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# real 64, 100, 150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inputs.shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0m_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rnn_impls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    129\u001b[0m             raise RuntimeError(\n\u001b[1;32m    130\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[0;32m--> 131\u001b[0;31m                     expected_input_dim, input.dim()))\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "train(model, optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
