{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_baseline_gpu_colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "t_bV546-3JVF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Импорты"
      ]
    },
    {
      "metadata": {
        "id": "SGIPKkSG3JVG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm_notebook, trange\n",
        "import pickle\n",
        "import numpy as np\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oa2jzP-N3JVI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1WoL992vCADZ",
        "colab_type": "code",
        "outputId": "89d26959-535a-4adb-d2f5-bfee1a1c38ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "jYSCFL3a7ISw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install telepyth -q\n",
        "\n",
        "from telepyth import TelepythClient\n",
        "\n",
        "tp = TelepythClient(\"14890519403566776828\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5tEoWJ7f3JVJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Предобработка"
      ]
    },
    {
      "metadata": {
        "id": "bnR1yqKZBiqi",
        "colab_type": "code",
        "outputId": "01d0634b-412c-4442-9eda-369f8a20a563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9NGHmxL23JVK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/My Drive/vkr'\n",
        "# code_batched = base_path + '/after_preprocess/after_preprocess.part0'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xr-HXCea3JVM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_vocab():\n",
        "    # load pre-computed vocab\n",
        "    with open(base_path + '/mapping.map', 'rb') as f:\n",
        "#         print(base_path + '/mapping.map')\n",
        "        word_to_id = pickle.load(f)\n",
        "    id_to_word = dict([(v, k) for (k, v) in word_to_id.items()])\n",
        "    return word_to_id, id_to_word\n",
        "\n",
        "word_to_id, id_to_word = build_vocab()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GPEXdVv13JVP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "params = {\n",
        "    'batch_size': 128,\n",
        "    'emb_size': 150,\n",
        "    'vocab_size': len(word_to_id),\n",
        "    # 'seq_len': 100,\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PoXTxkbv3JVR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def get_code_data(path):\n",
        "#     for _, _, files in os.walk(path):\n",
        "#         data = np.empty((0, 100))\n",
        "#         for file in tqdm_notebook(files):\n",
        "#             with open(path + file, 'rb') as f:\n",
        "#                 array = pickle.load(f)\n",
        "#                 for i in tqdm_notebook(range(len(array)), leave=False):\n",
        "#                     data = np.concatenate((data, array[i].inputs), axis=0)\n",
        "#     return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "colab_type": "code",
        "id": "Gk_DJThyY908",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# data = get_code_data(base_path + '/after_preprocess/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gPJNvogtY90O",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# with open('./after_preprocess/all_inputs', 'wb') as f:\n",
        "#     pickle.dump(data.astype('int64'), f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1s8xwzx5yr2f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# with open(data_path, 'rb') as f:\n",
        "#     bla = pickle.load(f)\n",
        "# len(bla)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ymRfG6ncyzMD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uswwMZXK3JVc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_path = base_path + '/after_preprocess/all_inputs'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uNIve_5psBqU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split threshold for train/test\n",
        "# approximately data contains 700k object\n",
        "split_num = int(700000 * 0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vm60u_JS3JVd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, path, params, start, end):\n",
        "        with open(path, 'rb') as f:\n",
        "            self.data = pickle.load(f)[start:end]\n",
        "\n",
        "    def __len__(self):\n",
        "#         return 10\n",
        "        return self.data.shape[0]\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6UpDAPXk3JVg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    CodeDataset(data_path, params, 0, split_num),\n",
        "    batch_size=params['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=10\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZKEk7sUHuJ0O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(\n",
        "    CodeDataset(data_path, params, split_num, None),\n",
        "    batch_size=params['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=10\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CDwQGSqL3JVo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Инициализация модели"
      ]
    },
    {
      "metadata": {
        "id": "MaZtCHSE3JVr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LstmBaseline(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super().__init__()\n",
        "        self.params = params\n",
        "        self.embedding = nn.Embedding(\n",
        "            self.params['vocab_size'],\n",
        "            self.params['emb_size']\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            self.params['emb_size'],\n",
        "            self.params['emb_size'],\n",
        "#             2\n",
        "            1\n",
        "        )\n",
        "        self.linear = nn.Linear(\n",
        "            self.params['emb_size'],\n",
        "            self.params['vocab_size']\n",
        "        )\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        pass\n",
        "\n",
        "    def forward(self, inputs, hidden):\n",
        "        embs = self.embedding(inputs)\n",
        "        # need 100, 64, 150(?)\n",
        "        # real 64, 100, 150\n",
        "        output, hidden = self.lstm.forward(embs, hidden)\n",
        "        output = self.linear(output)\n",
        "        return output, hidden\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rj-ngST93JVt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Обучение"
      ]
    },
    {
      "metadata": {
        "id": "wOt4O3yx3JVz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_epoch(model, optimizer, lr):\n",
        "    loss_log = []\n",
        "    model.train()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    \n",
        "    for batch_num, x in zip(trange(len(train_loader)), train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x = x.to(device)\n",
        "        loss_value = 0.\n",
        "        loss = nn.CrossEntropyLoss()\n",
        "        # todo check\n",
        "        hidden = None\n",
        "        for i in range(x.shape[1] - 1):\n",
        "            output, hidden = model.forward(x[:, i].unsqueeze(1), hidden)\n",
        "            loss_value += loss(output.squeeze(1), x[:, i + 1])\n",
        "            \n",
        "            _, arg_pred = torch.max(output.squeeze(1), 1)\n",
        "            eq_arr = arg_pred == x[:, i + 1]\n",
        "            total += eq_arr.shape[0]\n",
        "            correct += int(eq_arr.sum())\n",
        "        loss_value.backward()\n",
        "\n",
        "#         torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
        "#         for p in model.parameters():\n",
        "#             p.data.add_(-lr, p.grad.data)\n",
        "        optimizer.step()\n",
        "        loss_value = loss_value.item()\n",
        "        loss_log.append(loss_value)# / x.shape[1])\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy, loss_log\n",
        "\n",
        "def test(model):\n",
        "    loss_log = []\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_num, x in zip(trange(len(test_loader)), test_loader):\n",
        "        x = x.to(device)\n",
        "        loss_value = 0.\n",
        "        hidden = None\n",
        "        for i in range(x.shape[1] - 1):\n",
        "            output, hidden = model.forward(x[:, i].unsqueeze(1), hidden)\n",
        "            _, arg_pred = torch.max(output.squeeze(1), 1)\n",
        "            eq_arr = arg_pred == x[:, i + 1]\n",
        "            total += eq_arr.shape[0]\n",
        "            correct += int(eq_arr.sum())\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "def plot_history(train_history, title='loss'):\n",
        "    plt.figure()\n",
        "    plt.title('{}'.format(title))\n",
        "    plt.plot(train_history, label='train', zorder=1)\n",
        "    plt.xlabel('train steps')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "    \n",
        "def train(model, opt, n_epochs):\n",
        "    train_log = []\n",
        "    acc_log = []\n",
        "    lr = 0.05\n",
        "    lr_decay_base = 1 / 1.15\n",
        "    m_flat_lr = 20.0\n",
        "    for epoch in range(n_epochs):\n",
        "        lr_decay = lr_decay_base ** max(epoch - m_flat_lr, 0)\n",
        "        lr = lr * lr_decay\n",
        "        accuracy, train_loss = train_epoch(model, opt, lr)\n",
        "        train_log.extend(train_loss)\n",
        "        acc_log.append(accuracy)\n",
        "        torch.save(\n",
        "            {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': opt.state_dict(),\n",
        "                'loss': train_log[-1]\n",
        "            },\n",
        "            base_path + '/model_checkpoints2/lstm_baseline_checkpoint_{}.pt'.format(epoch)\n",
        "        )\n",
        "        clear_output()\n",
        "        print(\"Epoch:{}\".format(epoch))\n",
        "        print(\"Accuracy:\", accuracy)\n",
        "        tp.send_text('Epoch {}, LSTM baseline accuracy: {}'.format(epoch, accuracy))\n",
        "        plot_history(train_log)\n",
        "#     np.save(\"/home/.../model_checkpoints..._logs.npy\", np.array(train_log))\n",
        "#     np.save(\"/home/.../model_checkpoints..._logs_perp.npy\", np.array(perp_log))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZZFFiiIr3JV1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = LstmBaseline(params).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMVQ0GIc3JV2",
        "colab_type": "code",
        "outputId": "de72742d-355d-439b-ea03-06c019b289d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "train(model, optimizer, 5)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1\n",
            "Accuracy: 0.35851835690202705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "  7%|▋         | 254/3829 [05:57<1:23:40,  1.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b3a677923522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\\ntrain(model, optimizer, 5)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-e9bb377f07d1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, opt, n_epochs)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mlr_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_decay_base\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mm_flat_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mtrain_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0macc_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-e9bb377f07d1>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, lr)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0meq_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meq_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#         torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-FJhSgtPxOu6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0fd9a35f-9707-43d2-a5e9-d0959068ecc4"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "print('Accuracy:', test(model))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1607/1607 [16:32<00:00,  1.65it/s]\n",
            "Accuracy: 0.3440257559846452\n",
            "CPU times: user 11min 24s, sys: 5min 3s, total: 16min 27s\n",
            "Wall time: 16min 32s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}