{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook, trange, tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import keyword\n",
    "import tokenize\n",
    "from io import BytesIO\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1558273332.773469"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/Users/dentarasov/Yandex.Disk.localized/current/vkr'\n",
    "filenames_path = base_path + '/pycodesuggest_py_repos_normalised/train_files.txt'\n",
    "data_path = base_path + '/pycodesuggest_py_repos_normalised/'\n",
    "\n",
    "with open(filenames_path, 'r') as f:\n",
    "    filenames = f.read().split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tldr-pages/tldr/scripts/send_to_bot.py',\n",
       " 'tldr-pages/tldr/scripts/pdf/render.py']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_from_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            code = f.read()\n",
    "    except IsADirectoryError:\n",
    "        return []\n",
    "    keywords_list = []\n",
    "    g = tokenize.tokenize(BytesIO(code.encode(\"utf-8\")).readline)\n",
    "    for toktype, tokval, start, _, _ in g:\n",
    "        if toktype == tokenize.NAME and keyword.iskeyword(tokval):\n",
    "            keywords_list.append(tok2id[tokval])\n",
    "    return keywords_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False': 0,\n",
       " 'None': 1,\n",
       " 'True': 2,\n",
       " 'and': 3,\n",
       " 'as': 4,\n",
       " 'assert': 5,\n",
       " 'async': 6,\n",
       " 'await': 7,\n",
       " 'break': 8,\n",
       " 'class': 9,\n",
       " 'continue': 10,\n",
       " 'def': 11,\n",
       " 'del': 12,\n",
       " 'elif': 13,\n",
       " 'else': 14,\n",
       " 'except': 15,\n",
       " 'finally': 16,\n",
       " 'for': 17,\n",
       " 'from': 18,\n",
       " 'global': 19,\n",
       " 'if': 20,\n",
       " 'import': 21,\n",
       " 'in': 22,\n",
       " 'is': 23,\n",
       " 'lambda': 24,\n",
       " 'nonlocal': 25,\n",
       " 'not': 26,\n",
       " 'or': 27,\n",
       " 'pass': 28,\n",
       " 'raise': 29,\n",
       " 'return': 30,\n",
       " 'try': 31,\n",
       " 'while': 32,\n",
       " 'with': 33,\n",
       " 'yield': 34,\n",
       " 'BLANK': 35}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok2id = dict(zip(keyword.kwlist, range(len(keyword.kwlist))))\n",
    "tok2id['BLANK'] = len(keyword.kwlist)\n",
    "id2tok = dict(list(map(lambda x: x[::-1], list(tok2id.items()))))\n",
    "\n",
    "tok2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51889/51889 [06:53<00:00, 125.58it/s]  \n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "for filename in tqdm(filenames):\n",
    "    train += [get_keywords_from_file(data_path + filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames_path = base_path + '/pycodesuggest_py_repos_normalised/test_files.txt'\n",
    "\n",
    "with open(test_filenames_path, 'r') as f:\n",
    "    test_filenames = f.read().split('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39791/39791 [04:33<00:00, 145.69it/s]\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "for filename in tqdm(test_filenames):\n",
    "    test += [get_keywords_from_file(data_path + filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    'train': train,\n",
    "    'test': test,\n",
    "    'tok2id': tok2id,\n",
    "    'id2tok': id2tok\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_path + '/keywords_dataset.pickle', 'wb') as f:\n",
    "    pickle.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_path + '/keywords_dataset.pickle', 'rb') as f:\n",
    "    d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ngram():\n",
    "    def __init__(self, N, tok2id):\n",
    "        self.N = N\n",
    "        self.tok2id = tok2id\n",
    "        self.ngrams_dict = defaultdict(int)\n",
    "    \n",
    "    def process_train(self, train):\n",
    "        start_time = time.time()\n",
    "        for seq in train:\n",
    "            seq = [self.tok2id['BLANK'] for _ in range(self.N)] + seq\n",
    "            for i in range(len(seq) - self.N):\n",
    "                self.ngrams_dict[tuple(seq[i:i+self.N])] += 1\n",
    "#         print(seq, self.ngrams_dict)\n",
    "        self.filter_most_popular_ngrams()\n",
    "        print('Time spent {}s'.format(time.time() - start_time))\n",
    "    \n",
    "    def filter_most_popular_ngrams(self):\n",
    "        # ngram_list: [[(1, 231, 12), 5], ...]\n",
    "        ngrams_list = list(self.ngrams_dict.items())\n",
    "        def sort_fun(ngram):\n",
    "            return ngram[0][:self.N-1], ngram[1]\n",
    "        ngrams_list = sorted(ngrams_list, key=sort_fun, reverse=True)\n",
    "        prev = None\n",
    "        self.new_ngrams_dict = {}\n",
    "        for ngram in tqdm(ngrams_list):\n",
    "            cur = ngram[0][:self.N-1]\n",
    "            if prev != cur:\n",
    "                self.new_ngrams_dict[tuple(cur)] = ngram[0][self.N-1]\n",
    "            prev = cur\n",
    "    \n",
    "    def calc_accuracy(self, test):\n",
    "        tp = 0\n",
    "        count = 0\n",
    "        for seq in tqdm(test):\n",
    "            for i in range(len(seq)-self.N):\n",
    "                # to avoid considering empty tokens\n",
    "                # and non-identifiers\n",
    "                key = tuple(seq[i:i+self.N-1])\n",
    "                if key in self.new_ngrams_dict \\\n",
    "                    and seq[i+self.N-1] == self.new_ngrams_dict[key]:\n",
    "                    tp += 1\n",
    "                count += 1\n",
    "        return tp / count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1077/1077 [00:00<00:00, 916652.88it/s]\n",
      "  3%|▎         | 1189/39791 [00:00<00:03, 11833.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent 2.4231371879577637s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39791/39791 [00:02<00:00, 19552.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ngram = Ngram(2, d['tok2id'])\n",
    "ngram.process_train(d['train'])\n",
    "accuracy = ngram.calc_accuracy(d['test'])\n",
    "print('''Accuracy: {:.4f}'''.format(accuracy))\n",
    "# print('''Accuracy: {:.4f}\n",
    "# Time needed for one prediction is just accessing the dict element,\n",
    "# so it\\'s around ~12 sec / ~96000 = {:.7f} (info from tqdm counter)'''\\\n",
    "# .format(accuracy, 12. / 96000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16905/16905 [00:00<00:00, 1241828.98it/s]\n",
      "  3%|▎         | 1337/39791 [00:00<00:02, 13366.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent 2.4435698986053467s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39791/39791 [00:02<00:00, 18969.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ngram = Ngram(3, d['tok2id'])\n",
    "ngram.process_train(d['train'])\n",
    "accuracy = ngram.calc_accuracy(d['test'])\n",
    "print('''Accuracy: {:.4f}'''.format(accuracy))\n",
    "# print('''Accuracy: {:.4f}\n",
    "# Time needed for one prediction is just accessing the dict element,\n",
    "# so it\\'s around ~12 sec / ~96000 = {:.7f} (info from tqdm counter)'''\\\n",
    "# .format(accuracy, 12. / 96000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106273/106273 [00:00<00:00, 946852.58it/s]\n",
      "  3%|▎         | 1152/39791 [00:00<00:03, 11519.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent 3.037687063217163s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39791/39791 [00:02<00:00, 16595.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ngram = Ngram(4, d['tok2id'])\n",
    "ngram.process_train(d['train'])\n",
    "accuracy = ngram.calc_accuracy(d['test'])\n",
    "print('''Accuracy: {:.4f}'''.format(accuracy))\n",
    "# print('''Accuracy: {:.4f}\n",
    "# Time needed for one prediction is just accessing the dict element,\n",
    "# so it\\'s around ~12 sec / ~96000 = {:.7f} (info from tqdm counter)'''\\\n",
    "# .format(accuracy, 12. / 96000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams_dict = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seq in tqdm_notebook(train):\n",
    "#     for i in range(len(seq) - N):\n",
    "#         ngrams_dict[tuple(seq[i:i+N])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что стоит сделать\n",
    "* Убрать `<PAD>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_most_popular_ngrams(ngrams_dict):\n",
    "#     # ngram_list: [[(1, 231, 12), 5], ...]\n",
    "#     ngrams_list = list(ngrams_dict.items())\n",
    "#     def sort_fun(ngram):\n",
    "#         return ngram[0][:2], ngram[1]\n",
    "#     ngrams_list = sorted(ngrams_list, key=sort_fun, reverse=True)\n",
    "#     prev = None\n",
    "#     new_ngrams_dict = {}\n",
    "#     for ngram in tqdm(ngrams_list):\n",
    "#         cur = ngram[0][:2]\n",
    "#         if prev != cur:\n",
    "#             new_ngrams_dict[tuple(cur)] = ngram[0][2]\n",
    "#         prev = cur\n",
    "#     return new_ngrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_ngrams_dict = filter_most_popular_ngrams(ngrams_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./ngrams_dict.pickle', 'wb') as f:\n",
    "#     pickle.dump(new_ngrams_dict, f)\n",
    "\n",
    "with open('./ngrams_dict.pickle', 'rb') as f:\n",
    "    new_ngrams_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((79583, 14), 3),\n",
       " ((79583, 9), 2),\n",
       " ((79583, 5), 14),\n",
       " ((79583, 3), 2),\n",
       " ((79583, 2), 2),\n",
       " ((79581, 4), 1),\n",
       " ((79581, 3), 42671),\n",
       " ((79581, 2), 15),\n",
       " ((79580, 14), 7),\n",
       " ((79580, 9), 13)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(new_ngrams_dict.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab():\n",
    "    # load pre-computed vocab\n",
    "    with open(base_path + '/mapping.map', 'rb') as f:\n",
    "        word_to_id = pickle.load(f)\n",
    "    id_to_word = dict([(v, k) for (k, v) in word_to_id.items()])\n",
    "    return word_to_id, id_to_word\n",
    "\n",
    "word_to_id, id_to_word = build_vocab()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_quality(ngrams_dict):\n",
    "    tp = 0\n",
    "    count = 0\n",
    "    for seq in tqdm(test):\n",
    "        for i in range(len(seq)-N):\n",
    "            # to avoid considering empty tokens\n",
    "            # and non-identifiers\n",
    "            if seq[i+1] != 0 and seq[i+2] != 0 and keyword.iskeyword(id_to_word[seq[i+2]]):\n",
    "                if (seq[i], seq[i+1]) in ngrams_dict \\\n",
    "                        and seq[i+2] == ngrams_dict[(seq[i], seq[i+1])]:\n",
    "                    tp += 1\n",
    "                count += 1\n",
    "    return tp / count\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95687/95687 [00:09<00:00, 9885.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3511\n",
      "Time needed for one prediction is just accessing the dict element, so it's around ~12 sec / ~96000 = 0.0001250 (info from tqdm counter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = calc_quality(new_ngrams_dict)\n",
    "print('''Accuracy: {:.4f}\n",
    "Time needed for one prediction is just accessing the dict element, so it\\'s around ~12 sec / ~96000 = {:.7f} (info from tqdm counter)'''\\\n",
    ".format(accuracy, 12. / 96000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9281639"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape[0] * (test.shape[1] - N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
