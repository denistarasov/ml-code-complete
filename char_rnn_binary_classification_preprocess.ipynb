{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t_bV546-3JVF"
   },
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SGIPKkSG3JVG"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook, trange, tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5tEoWJ7f3JVJ"
   },
   "source": [
    "# Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "bnR1yqKZBiqi",
    "outputId": "01d0634b-412c-4442-9eda-369f8a20a563"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NGHmxL23JVK"
   },
   "outputs": [],
   "source": [
    "# base_path = '/content/drive/My Drive/vkr'\n",
    "base_path = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- брать код из обычных репозиториев, а разбивку — из нормализованных\n",
    "- сначала делаем выборку максимально без изворотов:\n",
    "    - каждый файл нарезаем на части по n символов в каждом, если в последнем куске не n — выбрасываем\n",
    "    - сохраняем выборку в файл pickle, пример: `[[\"import pickl\",1], ...]` (потому что дальше идет \"е\", вероятно)\n",
    "- преобразовать в удобный для модели формат:\n",
    "    - вместо строк — массив чисел, где каждое число биективно соответствует символу\n",
    "    \n",
    "- модель учится предсказывать n+1 символ, если он eng letter, то это 1, иначе 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessDataset():\n",
    "    def __init__(\n",
    "        self,\n",
    "        n,\n",
    "        path_to_filenames,\n",
    "        path_to_repo,\n",
    "        objects_limit,\n",
    "        check_if_english=True\n",
    "    ):\n",
    "        self.n = n\n",
    "        self.total_count = 0\n",
    "        self.pos_count = 0\n",
    "        with open(path_to_filenames, 'r') as f:\n",
    "            self.filenames = f.read().split('\\n')\n",
    "        self.path_to_repo = path_to_repo\n",
    "        self.dataset_dictionary = set()\n",
    "        self.objects_limit = objects_limit\n",
    "        self.check_if_english = check_if_english\n",
    "        self.allowed_letters = set(string.printable)\n",
    "\n",
    "    def update_dataset_dictionary(self, code):\n",
    "        self.dataset_dictionary.update(set(code))\n",
    "        \n",
    "    def is_english(self, code):\n",
    "        for char in code:\n",
    "            if char not in self.allowed_letters:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def process_code(self, code):\n",
    "        self.update_dataset_dictionary(code)\n",
    "        chunks, chunk_size = len(code), self.n\n",
    "        slices = [code[i:i+chunk_size] for i in range(0, chunks, chunk_size)]\n",
    "        self.total_count += len(slices) - 1\n",
    "        targets = []\n",
    "        for i in range(len(slices) - 1):\n",
    "            if slices[i+1][0].isalpha():\n",
    "                self.pos_count += 1\n",
    "                targets.append(True)\n",
    "            else:\n",
    "                targets.append(False)\n",
    "        slices = slices[:-1]\n",
    "        objects_from_code = list(zip(slices, targets))\n",
    "        return objects_from_code\n",
    "        \n",
    "    def make_dataset(self):\n",
    "        fidx = 0\n",
    "        pbar = tqdm(total=self.objects_limit)\n",
    "        objects_from_code = []\n",
    "        while self.total_count < self.objects_limit:\n",
    "            try:\n",
    "                with open(\n",
    "                    self.path_to_repo + self.filenames[fidx], 'r'\n",
    "                ) as code_file:\n",
    "                    code = code_file.read()\n",
    "            except IsADirectoryError:\n",
    "                fidx += 1\n",
    "                continue\n",
    "            fidx += 1\n",
    "            if self.check_if_english and not self.is_english(code):\n",
    "                continue\n",
    "            objects_from_code += self.process_code(code)\n",
    "            pbar.update(self.total_count)\n",
    "        pbar.close()\n",
    "#         print(objects_from_code)\n",
    "\n",
    "        print('Number of positives samples is {} out of {} ({:.2f}%)'.format(\n",
    "            self.pos_count,\n",
    "            self.total_count,\n",
    "            100. * self.pos_count / self.total_count\n",
    "        ))\n",
    "        \n",
    "#         print(len(self.dataset_dictionary), self.dataset_dictionary)\n",
    "        \n",
    "        return objects_from_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11942663337it [00:12, 963811656.23it/s]                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positives samples is 1051233 out of 2000054 (52.56%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prep_dataset = PreprocessDataset(\n",
    "    20,\n",
    "    base_path + '/pycodesuggest_py_repos_normalised/test_files.txt',\n",
    "    base_path + '/pycodesuggest_py_repos_normalised/',\n",
    "    objects_limit=2000000\n",
    ")\n",
    "objects_from_code = prep_dataset.make_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('from MyQR.terminal i', True),\n",
       " ('from MyQR.myqr impor', True),\n",
       " ('t run\\nimport os\\n\\n\\nde', True),\n",
       " ('f function1739():\\n  ', False),\n",
       " ('  import argparse\\n  ', False),\n",
       " ('  var2519 = argparse', False),\n",
       " ('.ArgumentParser()\\n  ', False),\n",
       " ('  var2519.add_argume', True),\n",
       " (\"nt('Words', help=\\n  \", False),\n",
       " (\"      'The words to \", True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects_from_code[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prep_dataset.dataset_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t',\n",
       " '\\n',\n",
       " '\\x0c',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_dataset.dataset_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_path + '/objects_from_code_test.pickle', 'wb') as f:\n",
    "    pickle.dump(objects_from_code, f)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm_baseline_gpu_colab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
