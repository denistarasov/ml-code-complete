{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t_bV546-3JVF"
   },
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SGIPKkSG3JVG"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook, trange, tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5tEoWJ7f3JVJ"
   },
   "source": [
    "# Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "bnR1yqKZBiqi",
    "outputId": "01d0634b-412c-4442-9eda-369f8a20a563"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NGHmxL23JVK"
   },
   "outputs": [],
   "source": [
    "# base_path = '/content/drive/My Drive/vkr'\n",
    "base_path = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- брать код из обычных репозиториев, а разбивку — из нормализованных\n",
    "- сначала делаем выборку максимально без изворотов:\n",
    "    - каждый файл нарезаем на части по n символов в каждом, если в последнем куске не n — выбрасываем\n",
    "    - сохраняем выборку в файл pickle, пример: `[[\"import pickl\",1], ...]` (потому что дальше идет \"е\", вероятно)\n",
    "- преобразовать в удобный для модели формат:\n",
    "    - вместо строк — массив чисел, где каждое число биективно соответствует символу\n",
    "    \n",
    "- модель учится предсказывать n+1 символ, если он eng letter, то это 1, иначе 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessDataset():\n",
    "    def __init__(\n",
    "        self,\n",
    "        n,\n",
    "        path_to_filenames,\n",
    "        path_to_repo,\n",
    "        objects_limit,\n",
    "        check_if_english=True\n",
    "    ):\n",
    "        self.n = n\n",
    "        self.total_count = 0\n",
    "        self.pos_count = 0\n",
    "        with open(path_to_filenames, 'r') as f:\n",
    "            self.filenames = f.read().split('\\n')\n",
    "        self.path_to_repo = path_to_repo\n",
    "        self.dataset_dictionary = set()\n",
    "        self.objects_limit = objects_limit\n",
    "        self.check_if_english = check_if_english\n",
    "        self.allowed_letters = set(string.printable)\n",
    "\n",
    "    def update_dataset_dictionary(self, code):\n",
    "        self.dataset_dictionary.update(set(code))\n",
    "        \n",
    "    def is_english(self, code):\n",
    "        for char in code:\n",
    "            if char not in self.allowed_letters:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def process_code(self, code):\n",
    "        self.update_dataset_dictionary(code)\n",
    "        chunks, chunk_size = len(code), self.n\n",
    "        slices = [code[i:i+chunk_size] for i in range(0, chunks, chunk_size)]\n",
    "        self.total_count += len(slices) - 1\n",
    "        targets = []\n",
    "        for i in range(len(slices) - 1):\n",
    "            if slices[i+1][0].isalpha():\n",
    "                self.pos_count += 1\n",
    "                targets.append(True)\n",
    "            else:\n",
    "                targets.append(False)\n",
    "        slices = slices[:-1]\n",
    "        objects_from_code = list(zip(slices, targets))\n",
    "        return objects_from_code\n",
    "        \n",
    "    def make_dataset(self):\n",
    "        fidx = 0\n",
    "        pbar = tqdm(total=self.objects_limit)\n",
    "        objects_from_code = []\n",
    "        while self.total_count < self.objects_limit:\n",
    "            with open(\n",
    "                self.path_to_repo + self.filenames[fidx],\n",
    "                'r'\n",
    "            ) as code_file:\n",
    "                code = code_file.read()\n",
    "            fidx += 1\n",
    "            if self.check_if_english and not self.is_english(code):\n",
    "                continue\n",
    "            objects_from_code += self.process_code(code)\n",
    "            pbar.update(self.total_count)\n",
    "        pbar.close()\n",
    "#         print(objects_from_code)\n",
    "\n",
    "        print('Number of positives samples is {} out of {} ({:.2f}%)'.format(\n",
    "            self.pos_count,\n",
    "            self.total_count,\n",
    "            100. * self.pos_count / self.total_count\n",
    "        ))\n",
    "        \n",
    "#         print(len(self.dataset_dictionary), self.dataset_dictionary)\n",
    "        \n",
    "        return objects_from_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31566657837it [00:25, 1221527424.58it/s]                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positives samples is 2565009 out of 5000289 (51.30%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prep_dataset = PreprocessDataset(\n",
    "    20,\n",
    "    base_path + '/pycodesuggest_py_repos_normalised/train_files.txt',\n",
    "    base_path + '/pycodesuggest_py_repos_normalised/',\n",
    "    objects_limit=5000000\n",
    ")\n",
    "objects_from_code = prep_dataset.make_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('import json\\nimport o', True),\n",
       " ('s\\nimport sys\\ntry:\\n  ', False),\n",
       " ('  import urllib.requ', True),\n",
       " ('est as urllib2\\nexcep', True),\n",
       " ('t ImportError:\\n    i', True),\n",
       " ('mport urllib2\\nvar266', False),\n",
       " (\"5 = 'https://tldr-bo\", True),\n",
       " ('t.starbeamrainbowlab', True),\n",
       " (\"s.com/'\\n\\n\\ndef functi\", True),\n",
       " ('on2743(arg1358, arg5', False)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects_from_code[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t',\n",
       " '\\n',\n",
       " '\\x0c',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_dataset.dataset_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_path + '/objects_from_code.pickle', 'wb') as f:\n",
    "    pickle.dump(objects_from_code, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = prep_dataset.dataset_dictionary\n",
    "tok2id = dict(zip(tokens, range(len(tokens))))\n",
    "id2tok = dict(list(map(lambda x: x[::-1], list(tok2id.items()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': 0,\n",
       " ' ': 1,\n",
       " 't': 2,\n",
       " '=': 3,\n",
       " '6': 4,\n",
       " 'X': 5,\n",
       " 'S': 6,\n",
       " '+': 7,\n",
       " 'x': 8,\n",
       " 's': 9,\n",
       " 'n': 10,\n",
       " '8': 11,\n",
       " '`': 12,\n",
       " '\\\\': 13,\n",
       " 'a': 14,\n",
       " 'I': 15,\n",
       " 'l': 16,\n",
       " 'G': 17,\n",
       " '#': 18,\n",
       " 'q': 19,\n",
       " 'M': 20,\n",
       " '/': 21,\n",
       " 'D': 22,\n",
       " 'z': 23,\n",
       " 'c': 24,\n",
       " 'R': 25,\n",
       " 'C': 26,\n",
       " 'v': 27,\n",
       " '.': 28,\n",
       " ',': 29,\n",
       " 'j': 30,\n",
       " 'L': 31,\n",
       " 'N': 32,\n",
       " ';': 33,\n",
       " ')': 34,\n",
       " 'K': 35,\n",
       " 'T': 36,\n",
       " '\\x0c': 37,\n",
       " '?': 38,\n",
       " 'J': 39,\n",
       " '9': 40,\n",
       " 'O': 41,\n",
       " '\"': 42,\n",
       " 'A': 43,\n",
       " '@': 44,\n",
       " '\\t': 45,\n",
       " '_': 46,\n",
       " '}': 47,\n",
       " 'i': 48,\n",
       " 'u': 49,\n",
       " '4': 50,\n",
       " '*': 51,\n",
       " 'k': 52,\n",
       " 'y': 53,\n",
       " 'F': 54,\n",
       " 'E': 55,\n",
       " 'g': 56,\n",
       " \"'\": 57,\n",
       " '&': 58,\n",
       " '-': 59,\n",
       " 'V': 60,\n",
       " '3': 61,\n",
       " 'W': 62,\n",
       " '2': 63,\n",
       " 'o': 64,\n",
       " '\\n': 65,\n",
       " '7': 66,\n",
       " '0': 67,\n",
       " '<': 68,\n",
       " '5': 69,\n",
       " 'Y': 70,\n",
       " 'r': 71,\n",
       " '[': 72,\n",
       " '1': 73,\n",
       " '(': 74,\n",
       " '|': 75,\n",
       " 'm': 76,\n",
       " '>': 77,\n",
       " '^': 78,\n",
       " 'h': 79,\n",
       " 'e': 80,\n",
       " '$': 81,\n",
       " 'd': 82,\n",
       " 'f': 83,\n",
       " '{': 84,\n",
       " 'U': 85,\n",
       " 'Q': 86,\n",
       " 'w': 87,\n",
       " 'H': 88,\n",
       " '~': 89,\n",
       " 'b': 90,\n",
       " '%': 91,\n",
       " '!': 92,\n",
       " 'P': 93,\n",
       " 'B': 94,\n",
       " ']': 95,\n",
       " ':': 96,\n",
       " 'Z': 97}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_for_model(code_samples):\n",
    "    max_len = len(code_samples[0][0])\n",
    "    converted_code = np.zeros([len(code_samples), max_len], np.int64)\n",
    "\n",
    "    for i in range(len(code_samples)):\n",
    "        obj = list(map(tok2id.get, code_samples[i][0]))\n",
    "        converted_code[i, :] = obj\n",
    "    targets = np.array(list(map(lambda pair: pair[1], code_samples)), np.bool)\n",
    "\n",
    "    return converted_code, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('import json\\nimport o', True), ('s\\nimport sys\\ntry:\\n  ', False), ('  import urllib.requ', True), ('est as urllib2\\nexcep', True), ('t ImportError:\\n    i', True), ('mport urllib2\\nvar266', False), (\"5 = 'https://tldr-bo\", True), ('t.starbeamrainbowlab', True), (\"s.com/'\\n\\n\\ndef functi\", True), ('on2743(arg1358, arg5', False)]\n",
      "(array([[48, 76,  0, 64, 71,  2,  1, 30,  9, 64, 10, 65, 48, 76,  0, 64,\n",
      "        71,  2,  1, 64],\n",
      "       [ 9, 65, 48, 76,  0, 64, 71,  2,  1,  9, 53,  9, 65,  2, 71, 53,\n",
      "        96, 65,  1,  1],\n",
      "       [ 1,  1, 48, 76,  0, 64, 71,  2,  1, 49, 71, 16, 16, 48, 90, 28,\n",
      "        71, 80, 19, 49],\n",
      "       [80,  9,  2,  1, 14,  9,  1, 49, 71, 16, 16, 48, 90, 63, 65, 80,\n",
      "         8, 24, 80,  0],\n",
      "       [ 2,  1, 15, 76,  0, 64, 71,  2, 55, 71, 71, 64, 71, 96, 65,  1,\n",
      "         1,  1,  1, 48],\n",
      "       [76,  0, 64, 71,  2,  1, 49, 71, 16, 16, 48, 90, 63, 65, 27, 14,\n",
      "        71, 63,  4,  4],\n",
      "       [69,  1,  3,  1, 57, 79,  2,  2,  0,  9, 96, 21, 21,  2, 16, 82,\n",
      "        71, 59, 90, 64],\n",
      "       [ 2, 28,  9,  2, 14, 71, 90, 80, 14, 76, 71, 14, 48, 10, 90, 64,\n",
      "        87, 16, 14, 90],\n",
      "       [ 9, 28, 24, 64, 76, 21, 57, 65, 65, 65, 82, 80, 83,  1, 83, 49,\n",
      "        10, 24,  2, 48],\n",
      "       [64, 10, 63, 66, 50, 61, 74, 14, 71, 56, 73, 61, 69, 11, 29,  1,\n",
      "        14, 71, 56, 69]]), array([ True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "       False]))\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "print(objects_from_code[:10])\n",
    "print(convert_for_model(objects_from_code[:10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 s, sys: 505 ms, total: 20.1 s\n",
      "Wall time: 20.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, y_train = convert_for_model(objects_from_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm_baseline_gpu_colab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
